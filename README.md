# Neural Phrase-To-Phrase Machine Translation implementation

Modèle de seq2seq learning basé sur des méchanismes d'attention.


## Sources intéressantes et état de l'art pour bien comprendre le modèle 


### Modèles de base sur Seq2seq et modèle d'attention
Seq2Seq Learning : Sutskever et al (2014) https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf
Attention based mechanism : Bahdhanau et al (2014) https://arxiv.org/pdf/1409.0473.pdf

### Architectures avancées qui utilisent des modèles d'attention
Papier sur les transformers : Attention is all you need https://arxiv.org/pdf/1706.03762.pdf


### Neural Phrase based-translation model 
Meilleur résultats sur les neural phrase based-translation model : Huang et al (2018) https://arxiv.org/pdf/1706.05565.pdf

